# -*- coding: utf-8 -*-
"""UseCase1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l07lFB-vxLcMr_I-Y0j-ityt0PcTA6qC
"""

import pandas as pd
import numpy as np
import random
import time
import math
from datetime import datetime, timedelta
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
import networkx as nx
from mlxtend.preprocessing import TransactionEncoder
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.cluster import MiniBatchKMeans
from sklearn.metrics.pairwise import linear_kernel

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

# Load the Netflix-Shows file
netflix_shows = pd.read_csv("netflix_titles.csv")

#mapping the multiple value cells into list type
netflix_shows['directors'] = netflix_shows['director'].apply(lambda l: [] if pd.isna(l) else [i.strip().replace(" ","_") for i in l.split(",")])
netflix_shows['genres'] = netflix_shows['listed_in'].apply(lambda l: [] if pd.isna(l) else [i.strip().replace(" ","_") for i in l.split(",")])
netflix_shows['actors'] = netflix_shows['cast'].apply(lambda l: [] if pd.isna(l) else [i.strip().replace(" ","_") for i in l.split(",")])
netflix_shows['countries'] = netflix_shows['country'].apply(lambda l: [] if pd.isna(l) else [i.strip().replace(" ","_") for i in l.split(",")])
netflix_shows['all_features'] = netflix_shows['directors'] + netflix_shows['genres'] + netflix_shows['actors'] + netflix_shows['countries']
netflix_shows['all_features'] = netflix_shows['all_features'].apply(lambda x: " ".join(x))

netflix_shows.head()

#Worldnet
nltk.download('wordnet')
nltk.download('stopwords')

def text_cleanser(text):
    stemmer = WordNetLemmatizer()
    text = ''.join([char for char in text if (char.isalpha() or char.isspace()) and char != "'"])
    text = [word.lower() for word in text.split() if word.lower() not in stopwords.words('english')]
    return [stemmer.lemmatize(word) for word in text]

netflix_shows_descriptions = netflix_shows[['show_id','description']].set_index('show_id')
netflix_shows_descriptions['trunc_desc'] = netflix_shows_descriptions['description'].apply(lambda x : text_cleanser(x))

# Finding TF and IDF metrics
vector = TfidfVectorizer(max_df=1.0, min_df=1,strip_accents = 'ascii', stop_words='english',lowercase=True,use_idf=True,norm=u'l2',smooth_idf=True)
tfidf = vector.fit_transform(netflix_shows.all_features)

#Clustering
k = 100
kmeans = MiniBatchKMeans(n_clusters = k, init = 'k-means++')
kmeans.fit(tfidf)
centers = kmeans.cluster_centers_.argsort()[:,::-1]
terms = vector.get_feature_names_out()
request_transform = vector.transform(netflix_shows['all_features'])

# new column cluster based on the description
netflix_shows['cluster'] = kmeans.predict(request_transform)

def find_similar_movies(tfidf_matrix, index, top_n = 5):
    cosine_similarities = linear_kernel(tfidf_matrix[index:index+1], tfidf_matrix).flatten()
    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]
    return [index for index in related_docs_indices][0:top_n]

#Create graph for related connecting movies

G = nx.Graph(label="SHOW")
start_time = time.time()
for i, rowi in netflix_shows.iterrows():
    G.add_node(rowi['title'],key=rowi['show_id'],label="SHOW",mtype=rowi['type'],rating=rowi['rating'])
    for element in rowi['actors']:
        G.add_node(element,label="PERSON")
        G.add_edge(rowi['title'], element, label="ACTED_IN")
    for element in rowi['genres']:
        G.add_node(element,label="GENRE")
        G.add_edge(rowi['title'], element, label="GENRE_IN")
    for element in rowi['directors']:
        G.add_node(element,label="PERSON")
        G.add_edge(rowi['title'], element, label="DIRECTED")
    for element in rowi['countries']:
        G.add_node(element,label="COU")
        G.add_edge(rowi['title'], element, label="COU_IN")

    indices = find_similar_movies(tfidf, i, top_n = 3)
    snode="Sim("+rowi['title'][:15].strip()+")"
    G.add_node(snode,label="SIMILAR")
    G.add_edge(rowi['title'], snode, label="SIMILARITY")
    for element in indices:
        G.add_edge(snode, netflix_shows['title'].loc[element], label="SIMILARITY")

#Generate a recommendation list based on the relationships between nodes in a graph.
def get_recommendation(root):
    commons_dict = {}
    for e in G.neighbors(root):
        for e2 in G.neighbors(e):
            if e2==root:
                continue
            if G.nodes[e2]['label']=="SHOW":
                commons = commons_dict.get(e2)
                if commons==None:
                    commons_dict.update({e2 : [e]})
                else:
                    commons.append(e)
                    commons_dict.update({e2 : commons})
    movies=[]
    weight=[]
    for key, values in commons_dict.items():
        w=0.0
        for e in values:
            w=w+1/math.log(G.degree(e))
        movies.append(key)
        weight.append(w)

    result = pd.Series(data=np.array(weight),index=movies)
    result.sort_values(inplace=True,ascending=False)
    return result

#Select Show
Movie="Chloe"

recommendation = get_recommendation(Movie)
recommendation.head(10)