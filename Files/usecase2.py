# -*- coding: utf-8 -*-
"""UseCase2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IShFDuFF1W42ucM_ikQUXAXYsEknJsxA
"""

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

import pandas as pd
import numpy as np
import random
import time
import math
from datetime import datetime, timedelta
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
import networkx as nx
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
import seaborn as sns

"""**CREATE MOCK DATA**"""

# Load the Netflix-Shows file
netflix_shows = pd.read_csv("netflix_titles.csv")

mock_df = pd.read_csv("mock_data.csv")

# Create list of movies watched by each user
user_movies_df = mock_df.groupby('Username')['Title'].apply(list).reset_index(name='Watched Movies')

user_movies_df['Watched Movies'] = user_movies_df['Watched Movies'].apply(lambda x: ','.join(x))

data_for_association = list(user_movies_df['Watched Movies'].apply(lambda x:x.split(",") ))

data_for_association[0:5]

# Convert dataset to TransactionEncoder format
a = TransactionEncoder()
a_data = a.fit(data_for_association).transform(data_for_association)
df_association = pd.DataFrame(a_data,columns=a.columns_)

df_association

fpgrowth_frequent_itemsets = fpgrowth(df_association, min_support=0.0001, use_colnames=True,max_len=2)
fpgrowth_frequent_itemsets

rules = association_rules(fpgrowth_frequent_itemsets,metric="lift",min_threshold=0.01)

rules

#SELECT SHOW

show = "Chloe"

rules[rules["antecedents"].apply(lambda x: frozenset([show]) == x)].sort_values(ascending=False,by='lift')

rules[rules["antecedents"].apply(lambda x: frozenset([show]) == x)].groupby(
    ['antecedents', 'consequents'])[['lift']].max().sort_values(ascending=False,by='lift')

rules[rules["antecedents"].apply(lambda x: frozenset([show]) == x)]\
    .groupby(['antecedents', 'consequents'])[['lift']].max()\
    .sort_values(by='lift', ascending=False)\
    .head(5)\
    .plot(kind='bar').invert_xaxis()
plt.title('Top movies that are likley to be watched with Chloe');

#Recommend show to the user based on lift values
def recommend_show(myshow,rule):
  recommended_shows = rule[rule["antecedents"].apply(lambda x: frozenset([myshow]) == x)]\
    .groupby(['antecedents', 'consequents'])[['lift']].max()\
    .sort_values(by='lift', ascending=False)\
    .head(5).reset_index()['consequents']

  print('Top movies that are likley to be watched with',myshow,':')
  for item in recommended_shows:
    print(*item)

#SELECT SHOW

show = "Alien TV"

recommend_show(show,rules)